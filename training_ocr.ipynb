{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import easyocr\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LicensePlateDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Get all image files and their labels\n",
    "        for img_path in self.data_dir.glob('*.*'):\n",
    "            if img_path.suffix.lower() in ['.png', '.jpg', '.jpeg']:\n",
    "                self.image_files.append(img_path)\n",
    "                self.labels.append(img_path.stem)  # Filename is the label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_files[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        # Convert to numpy array and normalize\n",
    "        image = np.array(image) / 255.0\n",
    "        # Convert to torch tensor and reshape to (C, H, W)\n",
    "        image = torch.FloatTensor(image).permute(2, 0, 1)\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "def create_dataloaders(base_path, batch_size=32):\n",
    "    # Create datasets\n",
    "    train_dataset = LicensePlateDataset(os.path.join(base_path, 'train'))\n",
    "    val_dataset = LicensePlateDataset(os.path.join(base_path, 'val'))\n",
    "    test_dataset = LicensePlateDataset(os.path.join(base_path, 'test'))\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def fine_tune_easyocr():\n",
    "    # Initialize EasyOCR reader with pretrained model\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    \n",
    "    # Configuration for fine-tuning\n",
    "    config = {\n",
    "        'learning_rate': 1e-4,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 50,\n",
    "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        'save_dir': 'fine_tuned_model',\n",
    "    }\n",
    "    \n",
    "    # Create save directory\n",
    "    os.makedirs(config['save_dir'], exist_ok=True)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(\n",
    "        'dataset',  # Your dataset path\n",
    "        batch_size=config['batch_size']\n",
    "    )\n",
    "    \n",
    "    # Get the recognition model from EasyOCR\n",
    "    recognition_model = reader.recognizer.model\n",
    "    recognition_model.to(config['device'])\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(recognition_model.parameters(), lr=config['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=0, reduction='mean')\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training\n",
    "        recognition_model.train()\n",
    "        train_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config[\"epochs\"]}')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            images = batch['image'].to(config['device'])\n",
    "            labels = batch['label']\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = recognition_model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        # Validation\n",
    "        recognition_model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(config['device'])\n",
    "                labels = batch['label']\n",
    "                outputs = recognition_model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': recognition_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }, os.path.join(config['save_dir'], 'best_model.pth'))\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Train Loss = {train_loss/len(train_loader):.4f}, '\n",
    "              f'Val Loss = {val_loss/len(val_loader):.4f}')\n",
    "def test_pretrained_model(test_dir: str) -> Tuple[float, List[Tuple[str, str, str]]]:\n",
    "    \"\"\"\n",
    "    Test pretrained EasyOCR model on test dataset\n",
    "    Returns accuracy and list of (filename, true_label, predicted_label)\n",
    "    \"\"\"\n",
    "    print(\"\\nTesting pretrained EasyOCR model...\")\n",
    "    \n",
    "    # Initialize EasyOCR reader\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    results = []\n",
    "    \n",
    "    # Get all test images\n",
    "    test_files = list(Path(test_dir).glob('*.*'))\n",
    "    test_files = [f for f in test_files if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in tqdm(test_files, desc=\"Processing test images\"):\n",
    "        true_label = img_path.stem\n",
    "        \n",
    "        # Read image with EasyOCR\n",
    "        predictions = reader.readtext(str(img_path))\n",
    "        \n",
    "        # Get the text with highest confidence if any predictions exist\n",
    "        if predictions:\n",
    "            predicted_label = predictions[0][1].upper()  # Convert to uppercase for comparison\n",
    "        else:\n",
    "            predicted_label = \"\"\n",
    "        \n",
    "        # Store result\n",
    "        results.append((img_path.name, true_label, predicted_label))\n",
    "        \n",
    "        # Update accuracy\n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nPretrained Model Results:\")\n",
    "    print(f\"Total images processed: {total}\")\n",
    "    print(f\"Correct predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"Average time per image: {processing_time/total:.2f} seconds\")\n",
    "    \n",
    "    # Print some example predictions\n",
    "    print(\"\\nSample Predictions (first 10):\")\n",
    "    print(\"Filename | True Label | Predicted Label\")\n",
    "    print(\"-\" * 50)\n",
    "    for filename, true, pred in results[:10]:\n",
    "        print(f\"{filename} | {true} | {pred}\")\n",
    "    \n",
    "    return accuracy, results\n",
    "\n",
    "def test_fine_tuned_model(model_path, test_loader):\n",
    "    # Load the fine-tuned model\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    recognition_model = reader.recognizer.model\n",
    "    \n",
    "    checkpoint = torch.load(model_path)\n",
    "    recognition_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    recognition_model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            images = batch['image']\n",
    "            labels = batch['label']\n",
    "            outputs = recognition_model(images)\n",
    "            predictions = outputs.argmax(dim=2)\n",
    "            \n",
    "            # Compare predictions with labels\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            total += labels.numel()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_fine_tuned_model(model_path: str, test_dir: str):\n",
    "#     \"\"\"\n",
    "#     Test fine-tuned model and compare with pretrained results\n",
    "#     \"\"\"\n",
    "#     print(\"\\nTesting fine-tuned model...\")\n",
    "    \n",
    "#     # Load the checkpoint\n",
    "#     checkpoint = torch.load(model_path)\n",
    "#     pretrained_accuracy = checkpoint.get('pretrained_accuracy', 0)\n",
    "    \n",
    "#     # Initialize reader with fine-tuned model\n",
    "#     reader = easyocr.Reader(['en'])\n",
    "#     recognition_model = reader.recognizer.model\n",
    "#     recognition_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     recognition_model.eval()\n",
    "    \n",
    "#     # Test the model\n",
    "#     accuracy, results = test_pretrained_model(test_dir)\n",
    "    \n",
    "#     # Print comparison\n",
    "#     print(\"\\nModel Comparison:\")\n",
    "#     print(f\"Pretrained model accuracy: {pretrained_accuracy:.4f}\")\n",
    "#     print(f\"Fine-tuned model accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"Improvement: {(accuracy - pretrained_accuracy)*100:.2f}%\")\n",
    "    \n",
    "#     return accuracy, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_fine_tuned_model(test_dir: str, model_path: str) -> Tuple[float, List[Tuple[str, str, str]]]:\n",
    "    \"\"\"\n",
    "    Test fine-tuned EasyOCR model on test dataset using the same methodology as pretrained testing\n",
    "    Returns accuracy and list of (filename, true_label, predicted_label)\n",
    "    \"\"\"\n",
    "    print(\"\\nTesting fine-tuned EasyOCR model...\")\n",
    "    \n",
    "    # Initialize EasyOCR reader with custom model\n",
    "    reader = easyocr.Reader(\n",
    "        ['en'],\n",
    "        model_storage_directory=os.path.dirname(model_path),\n",
    "        user_network_directory=True,\n",
    "        recog_network='Transformer'  # Should match your model name\n",
    "    )\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    results = []\n",
    "    \n",
    "    # Get all test images\n",
    "    test_files = list(Path(test_dir).glob('*.*'))\n",
    "    test_files = [f for f in test_files if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Process each image\n",
    "    for img_path in tqdm(test_files, desc=\"Processing test images\"):\n",
    "        true_label = img_path.stem\n",
    "        \n",
    "        try:\n",
    "            # Read image with fine-tuned EasyOCR\n",
    "            predictions = reader.readtext(str(img_path))\n",
    "            \n",
    "            # Get the text with highest confidence if any predictions exist\n",
    "            if predictions:\n",
    "                predicted_label = predictions[0][1].upper()  # Convert to uppercase for comparison\n",
    "                confidence = predictions[0][2]  # Get confidence score\n",
    "            else:\n",
    "                predicted_label = \"\"\n",
    "                confidence = 0.0\n",
    "            \n",
    "            # Store result\n",
    "            results.append((img_path.name, true_label, predicted_label))\n",
    "            \n",
    "            # Update accuracy\n",
    "            if predicted_label == true_label:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\nFine-tuned Model Results:\")\n",
    "    print(f\"Total images processed: {total}\")\n",
    "    print(f\"Correct predictions: {correct}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    print(f\"Average time per image: {processing_time/total:.2f} seconds\")\n",
    "    \n",
    "    # Print some example predictions\n",
    "    print(\"\\nSample Predictions (first 10):\")\n",
    "    print(\"Filename | True Label | Predicted Label\")\n",
    "    print(\"-\" * 50)\n",
    "    for filename, true, pred in results[:10]:\n",
    "        print(f\"{filename} | {true} | {pred}\")\n",
    "    \n",
    "    return accuracy, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Number of GPUs: {torch.cuda.device_count()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, test_loader = create_dataloaders('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing pretrained EasyOCR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test images: 100%|██████████| 73/73 [00:04<00:00, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pretrained Model Results:\n",
      "Total images processed: 73\n",
      "Correct predictions: 1\n",
      "Accuracy: 0.0137\n",
      "Processing time: 4.58 seconds\n",
      "Average time per image: 0.06 seconds\n",
      "\n",
      "Sample Predictions (first 10):\n",
      "Filename | True Label | Predicted Label\n",
      "--------------------------------------------------\n",
      "1033IR.png | 1033IR | N0\n",
      "2348XR25.jpg | 2348XR25 | D210\n",
      "34EN9199.png | 34EN9199 | TRI\n",
      "381ATK83_1.png | 381ATK83_1 | 381 ATK 83\n",
      "55SG53.jpg | 55SG53 | 55\n",
      "5658YA22.jpg | 5658YA22 | 6658Y42\n",
      "5888881.png | 5888881 | 58088881\n",
      "5B40001.png | 5B40001 | 5B4\n",
      "75N1960G.png | 75N1960G | F\n",
      "8427XX29.jpg | 8427XX29 | [427 XX29\n",
      "\n",
      "Testing fine-tuned EasyOCR model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m pretrained_accuracy, pretrained_results \u001b[38;5;241m=\u001b[39m test_pretrained_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m finetuned_accuracy, finetuned_results \u001b[38;5;241m=\u001b[39m \u001b[43mtest_fine_tuned_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModel/english_g2.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 9\u001b[0m, in \u001b[0;36mtest_fine_tuned_model\u001b[1;34m(test_dir, model_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTesting fine-tuned EasyOCR model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Initialize EasyOCR reader with custom model\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_storage_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_network_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecog_network\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Should match your model name\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     17\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32md:\\Project\\License_plate\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:65\u001b[0m, in \u001b[0;36mReader.__init__\u001b[1;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_network_directory:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_network_directory \u001b[38;5;241m=\u001b[39m user_network_directory\n\u001b[1;32m---> 65\u001b[0m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_network_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_network_directory)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:871\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[1;32m--> 871\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:509\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 509\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:493\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    491\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     a \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(a)\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not bool"
     ]
    }
   ],
   "source": [
    "pretrained_accuracy, pretrained_results = test_pretrained_model('dataset/test')\n",
    "finetuned_accuracy, finetuned_results = test_fine_tuned_model(\n",
    "    test_dir='dataset/test',\n",
    "    model_path='Model/english_g2.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m reader \u001b[38;5;241m=\u001b[39m \u001b[43measyocr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_storage_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProject\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mLicense_plate\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_network_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrecog_network\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransformer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Should match your model name\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Project\\License_plate\\.venv\\Lib\\site-packages\\easyocr\\easyocr.py:65\u001b[0m, in \u001b[0;36mReader.__init__\u001b[1;34m(self, lang_list, gpu, model_storage_directory, user_network_directory, detect_network, recog_network, download_enabled, detector, recognizer, verbose, quantize, cudnn_benchmark)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_network_directory:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_network_directory \u001b[38;5;241m=\u001b[39m user_network_directory\n\u001b[1;32m---> 65\u001b[0m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_network_directory\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_network_directory)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:871\u001b[0m, in \u001b[0;36mPath.__new__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[1;32m--> 871\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:509\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m--> 509\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\pathlib.py:493\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[1;34m(cls, args)\u001b[0m\n\u001b[0;32m    491\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 493\u001b[0m     a \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(a)\n\u001b[0;32m    494\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    495\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not bool"
     ]
    }
   ],
   "source": [
    "    reader = easyocr.Reader(\n",
    "        ['en'],\n",
    "        model_storage_directory=os.path.dirname(r\"D:\\Project\\License_plate\\Model\"),\n",
    "        user_network_directory=True,\n",
    "        recog_network='Transformer'  # Should match your model name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
